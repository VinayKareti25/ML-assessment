{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990fb2aa",
   "metadata": {},
   "source": [
    "# Healthcare Readmission Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30447a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5a83b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (101766, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Load Dataset\n",
    "df = pd.read_csv('diabetic_data.csv')\n",
    "print(\"Shape of data:\", df.shape)\n",
    "df = df.replace('?', np.nan)\n",
    "df = df.drop(columns=['weight', 'payer_code', 'medical_specialty', 'encounter_id', 'patient_nbr'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e02e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Data Types and Target Setup\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "df['readmitted'] = df['readmitted'].map({'NO':0, '>30':1, '<30':1})\n",
    "y = df['readmitted']\n",
    "X = df.drop(columns=['readmitted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50401a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (71236, 44) Validation: (15265, 44) Test: (15265, 44)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Handle time-based numeric features if any\n",
    "if 'admission_type_id' in X.columns:\n",
    "    X['admission_type_id'] = X['admission_type_id'].astype(int)\n",
    "if 'discharge_disposition_id' in X.columns:\n",
    "    X['discharge_disposition_id'] = X['discharge_disposition_id'].astype(int)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Validation:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffdd686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected categorical columns: 33\n",
      "Detected numerical columns: 11\n",
      "✅ Preprocessor successfully created with available columns.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Step 5 (Fixed): Dynamic Preprocessing Setup\n",
    "# Automatically detect valid columns and handle mixed data safely\n",
    "\n",
    "# Re-identify columns after cleaning\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
    "numerical_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
    "\n",
    "print(\"Detected categorical columns:\", len(categorical_cols))\n",
    "print(\"Detected numerical columns:\", len(numerical_cols))\n",
    "\n",
    "# Handle edge cases (e.g., no numeric or no categorical columns)\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', StandardScaler())\n",
    "]) if len(numerical_cols) > 0 else 'drop'\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "]) if len(categorical_cols) > 0 else 'drop'\n",
    "\n",
    "# Only include valid transformers\n",
    "transformers = []\n",
    "if len(numerical_cols) > 0:\n",
    "    transformers.append(('num', numeric_transformer, numerical_cols))\n",
    "if len(categorical_cols) > 0:\n",
    "    transformers.append(('cat', categorical_transformer, categorical_cols))\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=transformers)\n",
    "print(\"✅ Preprocessor successfully created with available columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0623a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    'SVM': SVC(probability=True, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest...\n",
      "RandomForest: Brier=0.2205, AUC=0.6925, Accuracy=0.6437\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost: Brier=0.2163, AUC=0.7049, Accuracy=0.6474\n",
      "\n",
      "Training SVM...\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Train, Calibrate (robust to sklearn version) ---\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score, accuracy_score\n",
    "from sklearn.base import clone\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure labels are integer\n",
    "y_train = y_train.astype(int)\n",
    "y_val   = y_val.astype(int)\n",
    "y_test  = y_test.astype(int)\n",
    "\n",
    "# Fit the preprocessor on training data and transform all sets\n",
    "X_train_tr = preprocessor.fit_transform(X_train)\n",
    "X_val_tr   = preprocessor.transform(X_val)\n",
    "X_test_tr  = preprocessor.transform(X_test)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    # clone the model to ensure a fresh unfitted estimator each loop\n",
    "    clf = clone(model)\n",
    "\n",
    "    # fit base model on transformed training data\n",
    "    clf.fit(X_train_tr, y_train)\n",
    "\n",
    "    # wrap the fitted classifier with CalibratedClassifierCV using prefit mode\n",
    "    # newer sklearn versions use `estimator=`, older versions use `base_estimator=`\n",
    "    try:\n",
    "        calibrator = CalibratedClassifierCV(estimator=clf, cv='prefit', method='isotonic')\n",
    "    except TypeError:\n",
    "        # fallback for older sklearn releases\n",
    "        calibrator = CalibratedClassifierCV(base_estimator=clf, cv='prefit', method='isotonic')\n",
    "\n",
    "    # Calibrate using the validation set\n",
    "    calibrator.fit(X_val_tr, y_val)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_proba = calibrator.predict_proba(X_test_tr)[:, 1]\n",
    "    y_pred  = (y_proba > 0.5).astype(int)\n",
    "\n",
    "    brier = brier_score_loss(y_test, y_proba)\n",
    "    auc   = roc_auc_score(y_test, y_proba)\n",
    "    acc   = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {'Brier': brier, 'AUC': auc, 'Accuracy': acc}\n",
    "    print(f\"{name}: Brier={brier:.4f}, AUC={auc:.4f}, Accuracy={acc:.4f}\")\n",
    "\n",
    "# summary\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\\n\", results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390eaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Calibration Curves\n",
    "plt.figure(figsize=(7,5))\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label=name)\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.title(\"Calibration Curves\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"True Probability\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Feature Importance (Random Forest)\n",
    "rf_pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', RandomForestClassifier(random_state=42))])\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "rf_model = rf_pipe.named_steps['model']\n",
    "\n",
    "if hasattr(rf_model, 'feature_importances_'):\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_names = rf_pipe.named_steps['preprocessor'].get_feature_names_out()\n",
    "    feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)[:20]\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x=feat_imp.values, y=feat_imp.index)\n",
    "    plt.title(\"Top 20 Important Features\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9: Clinical Utility Summary\n",
    "print(\"=== Clinical Utility Summary ===\")\n",
    "print(\"The best calibrated model provides reliable probability estimates for hospital readmission.\")\n",
    "print(\"Top predictors may include medication changes, lab procedures, and number of inpatient visits.\")\n",
    "print(\"These can guide follow-up scheduling and preventive care.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
